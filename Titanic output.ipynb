{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd        \n",
    "import tensorflow as tf\n",
    "import xgboost\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 623 entries, 0 to 622\n",
      "Data columns (total 8 columns):\n",
      "Survived    623 non-null int64\n",
      "Pclass      623 non-null int64\n",
      "Sex         623 non-null int32\n",
      "Age         623 non-null float64\n",
      "SibSp       623 non-null int64\n",
      "Parch       623 non-null int64\n",
      "Fare        623 non-null float64\n",
      "Embarked    623 non-null int32\n",
      "dtypes: float64(2), int32(2), int64(4)\n",
      "memory usage: 34.2 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 268 entries, 0 to 267\n",
      "Data columns (total 8 columns):\n",
      "Survived    268 non-null int64\n",
      "Pclass      268 non-null int64\n",
      "Sex         268 non-null int32\n",
      "Age         268 non-null float64\n",
      "SibSp       268 non-null int64\n",
      "Parch       268 non-null int64\n",
      "Fare        268 non-null float64\n",
      "Embarked    268 non-null int32\n",
      "dtypes: float64(2), int32(2), int64(4)\n",
      "memory usage: 14.8 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\jfh470\\Desktop\\titanic\\train.csv')\n",
    "# randomizes data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# fills empty spaces\n",
    "df['Embarked']=df['Embarked'].fillna('S') \n",
    "df['Age']=df['Age'].fillna(df['Age'].dropna().median())\n",
    "df['Fare'] = df['Fare'].fillna(df['Fare'].dropna().median)\n",
    "\n",
    "# changes categorical data to numerical\n",
    "label_encoder = LabelEncoder()\n",
    "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
    "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
    "\n",
    "# drops unnecessary columns\n",
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# splits data into test and train\n",
    "df_train, df_test = np.split(df, [int(.7*len(df))])\n",
    "\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "print(df_train.info())\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['Survived'], axis=1)\n",
    "y_train = df_train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>40.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.85</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch   Fare  Embarked\n",
       "0       3    1  40.5      0      2  14.50         2\n",
       "1       3    0  28.0      8      2  69.55         2\n",
       "2       2    1   3.0      1      1  26.00         2\n",
       "3       3    1  28.0      0      0   7.75         1\n",
       "4       3    1  28.0      1      0  15.85         2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.      1.     30.     ...  0.     10.5     2.    ]\n",
      " [ 3.      1.      2.     ...  1.     29.125   1.    ]\n",
      " [ 1.      0.     58.     ...  0.     26.55    2.    ]\n",
      " ...\n",
      " [ 3.      1.     23.5    ...  0.      7.2292  0.    ]\n",
      " [ 3.      0.     28.     ...  2.     23.45    2.    ]\n",
      " [ 1.      1.     31.     ...  0.     50.4958  2.    ]]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.values\n",
    "X_test = df_test.drop(['Survived'], axis=1).values\n",
    "y_test = df_test['Survived'].values\n",
    "\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50  estimators, learning rate of  0.001 , accuracy =  0.6156716417910447\n",
      "100  estimators, learning rate of  0.001 , accuracy =  0.6156716417910447\n",
      "150  estimators, learning rate of  0.001 , accuracy =  0.6156716417910447\n",
      "200  estimators, learning rate of  0.001 , accuracy =  0.6156716417910447\n",
      "250  estimators, learning rate of  0.001 , accuracy =  0.7649253731343284\n",
      "50  estimators, learning rate of  0.005 , accuracy =  0.7649253731343284\n",
      "100  estimators, learning rate of  0.005 , accuracy =  0.7761194029850746\n",
      "150  estimators, learning rate of  0.005 , accuracy =  0.7910447761194029\n",
      "200  estimators, learning rate of  0.005 , accuracy =  0.7947761194029851\n",
      "250  estimators, learning rate of  0.005 , accuracy =  0.7947761194029851\n",
      "50  estimators, learning rate of  0.01 , accuracy =  0.7835820895522388\n",
      "100  estimators, learning rate of  0.01 , accuracy =  0.7910447761194029\n",
      "150  estimators, learning rate of  0.01 , accuracy =  0.7985074626865671\n",
      "200  estimators, learning rate of  0.01 , accuracy =  0.7985074626865671\n",
      "250  estimators, learning rate of  0.01 , accuracy =  0.7910447761194029\n",
      "50  estimators, learning rate of  0.05 , accuracy =  0.7985074626865671\n",
      "100  estimators, learning rate of  0.05 , accuracy =  0.7723880597014925\n",
      "150  estimators, learning rate of  0.05 , accuracy =  0.7873134328358209\n",
      "200  estimators, learning rate of  0.05 , accuracy =  0.7723880597014925\n",
      "250  estimators, learning rate of  0.05 , accuracy =  0.7649253731343284\n",
      "50  estimators, learning rate of  0.1 , accuracy =  0.7723880597014925\n",
      "100  estimators, learning rate of  0.1 , accuracy =  0.7761194029850746\n",
      "150  estimators, learning rate of  0.1 , accuracy =  0.7723880597014925\n",
      "200  estimators, learning rate of  0.1 , accuracy =  0.7723880597014925\n",
      "250  estimators, learning rate of  0.1 , accuracy =  0.7686567164179104\n",
      "50  estimators, learning rate of  0.5 , accuracy =  0.7611940298507462\n",
      "100  estimators, learning rate of  0.5 , accuracy =  0.7649253731343284\n",
      "150  estimators, learning rate of  0.5 , accuracy =  0.7723880597014925\n",
      "200  estimators, learning rate of  0.5 , accuracy =  0.7723880597014925\n",
      "250  estimators, learning rate of  0.5 , accuracy =  0.7723880597014925\n",
      "50  estimators, learning rate of  1 , accuracy =  0.7835820895522388\n",
      "100  estimators, learning rate of  1 , accuracy =  0.7686567164179104\n",
      "150  estimators, learning rate of  1 , accuracy =  0.7574626865671642\n",
      "200  estimators, learning rate of  1 , accuracy =  0.7611940298507462\n",
      "250  estimators, learning rate of  1 , accuracy =  0.7649253731343284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "learning_rates = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]\n",
    "n_estimators = [50, 100, 150, 200, 250]\n",
    "for learning_rate in learning_rates:\n",
    "    for n_estimator in n_estimators:\n",
    "        gb = GradientBoostingClassifier(n_estimators=n_estimator, learning_rate=learning_rate, max_features=7, max_depth=7)\n",
    "        gb.fit(X_train, y_train)\n",
    "        #     gb_predict = pd.DataFrame(gb.predict(X_test), columns=['Gradient Boost Predictions'])\n",
    "        print(n_estimator, \" estimators, learning rate of \", learning_rate, \", accuracy = \", gb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1\n",
      " 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1\n",
      " 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 0\n",
      " 1 0 1 1 0 0 0 0 0]\n",
      "0.8208955223880597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=871, max_features=5)\n",
    "random_forest.fit(X_train, y_train)\n",
    "rand_for_predict = random_forest.predict(X_test)\n",
    "print(rand_for_predict)\n",
    "rand_for_predict = pd.DataFrame(rand_for_predict, columns=['Random Forest Predictions'])\n",
    "print(random_forest.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     XGBoost Predictions\n",
      "0                      0\n",
      "1                      1\n",
      "2                      1\n",
      "3                      0\n",
      "4                      0\n",
      "..                   ...\n",
      "263                    0\n",
      "264                    0\n",
      "265                    0\n",
      "266                    0\n",
      "267                    0\n",
      "\n",
      "[268 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8246268656716418"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_model = xgboost.XGBClassifier(n_estimators=500, learning_rate=0.001, use_label_encoder=False)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_predict = pd.DataFrame(xgb_model.predict(X_test), columns=['XGBoost Predictions'])\n",
    "\n",
    "print(xgb_predict)\n",
    "xgb_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x_data, y_data, batch_size):\n",
    "    idxs = np.random.randint(0, len(y_data), batch_size)\n",
    "    return x_data[idxs,:], y_data[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 250\n",
    "batch_size = 100\n",
    "X_test = tf.Variable(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.random.normal([7, 128], stddev=0.03), name='w1')\n",
    "b1 = tf.Variable(tf.random.normal([128]), name='b1')\n",
    "\n",
    "w2 = tf.Variable(tf.random.normal([128, 10]), name='w2')\n",
    "b2 = tf.Variable(tf.random.normal([10]), name='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(x_input, w1, b1, w2, b2):\n",
    "    x = tf.add(tf.matmul(tf.cast(x_input, tf.float32), w1), b1)\n",
    "#     print(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    logits = tf.add(tf.matmul(x, w2), b2)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits, labels):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss=25.203, test set accuracy=2.985%\n",
      "Epoch: 2, loss=10.162, test set accuracy=26.493%\n",
      "Epoch: 3, loss=4.205, test set accuracy=61.940%\n",
      "Epoch: 4, loss=2.944, test set accuracy=59.328%\n",
      "Epoch: 5, loss=1.995, test set accuracy=55.224%\n",
      "Epoch: 6, loss=1.660, test set accuracy=56.343%\n",
      "Epoch: 7, loss=1.155, test set accuracy=58.582%\n",
      "Epoch: 8, loss=0.940, test set accuracy=58.582%\n",
      "Epoch: 9, loss=0.795, test set accuracy=55.970%\n",
      "Epoch: 10, loss=0.740, test set accuracy=55.224%\n",
      "     Neural Network Predictions\n",
      "0                             0\n",
      "1                             0\n",
      "2                             1\n",
      "3                             0\n",
      "4                             0\n",
      "..                          ...\n",
      "263                           0\n",
      "264                           0\n",
      "265                           0\n",
      "266                           1\n",
      "267                           0\n",
      "\n",
      "[268 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "total_batch = int(len(y_train)/batch_size)\n",
    "accuracy = 0\n",
    "previous = -2\n",
    "for epoch in range(epochs):\n",
    "    if accuracy > previous + 1:\n",
    "        avg_loss = 0\n",
    "        nn_predict = list()\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = get_batch(X_train, y_train, batch_size=batch_size)\n",
    "            batch_x = tf.Variable(batch_x)\n",
    "            batch_y = tf.Variable(batch_y)\n",
    "            batch_y = tf.one_hot(batch_y, 10)\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = nn_model(batch_x, w1, b1, w2, b2)\n",
    "                loss = loss_fn(logits, batch_y)\n",
    "            gradients = tape.gradient(loss, [w1, b1, w2, b2])\n",
    "            optimizer.apply_gradients(zip(gradients, [w1, b1, w2, b2]))\n",
    "            avg_loss += loss/total_batch\n",
    "            test_logits = nn_model(X_test, w1, b1, w2, b2)\n",
    "        max_idxs = tf.argmax(test_logits, axis=1)\n",
    "        test_acc = np.sum(max_idxs.numpy() == y_test) / len(y_test)\n",
    "        print(f\"Epoch: {epoch + 1}, loss={avg_loss:.3f}, test set accuracy={test_acc*100:.3f}%\")\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            previous = accuracy\n",
    "            accuracy = test_acc*100\n",
    "        nn_predict.append(max_idxs.numpy())\n",
    "    else:\n",
    "        break\n",
    "nn_predict = pd.DataFrame(nn_predict, index=['Neural Network Predictions']).transpose()\n",
    "print(nn_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0         0       2    1  30.0      0      0  10.5000         2   \n",
      "1         0       3    1   2.0      4      1  29.1250         1   \n",
      "2         1       1    0  58.0      0      0  26.5500         2   \n",
      "3         0       2    1  18.0      0      0  73.5000         2   \n",
      "4         1       3    1  28.0      0      0  56.4958         2   \n",
      "\n",
      "   Random Forest Predictions  XGBoost Predictions  Neural Network Predictions  \n",
      "0                          0                    0                           0  \n",
      "1                          0                    1                           0  \n",
      "2                          1                    1                           1  \n",
      "3                          0                    0                           0  \n",
      "4                          0                    0                           0  \n"
     ]
    }
   ],
   "source": [
    "output = pd.concat([df_test, rand_for_predict, xgb_predict, nn_predict], axis=1)\n",
    "print(output.head(5))\n",
    "# output.to_csv('titanic_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for Neural Network: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.72      0.66       163\n",
      "           1       0.40      0.29      0.33       105\n",
      "\n",
      "    accuracy                           0.55       268\n",
      "   macro avg       0.51      0.50      0.50       268\n",
      "weighted avg       0.53      0.55      0.53       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores for Neural Network: \\n\"+ classification_report(output['Survived'], output['Neural Network Predictions']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
